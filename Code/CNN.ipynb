{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 4, stride=(1,2))\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.poolLast = nn.MaxPool2d(2,2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 6)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 6)\n",
    "        self.fc1 = nn.Linear(2816, 32)\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "        self.dropoutConv = nn.Dropout2d(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.conv1.bias.dtype)\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropoutConv(x)\n",
    "        x = self.pool(F.relu(x)) # 200x104 -> 197x51 -> 199x53 -> 99x26\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropoutConv(x)\n",
    "        x = self.pool(F.relu(x)) # 99x26 -> 95x22 -> 97x24 -> 48 x 12\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropoutConv(x)\n",
    "        x = self.poolLast(F.relu(x)) # 48x12 -> 44x8 -> 22x4\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch -> 88*Channels\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "train_dataset = torch.load('/content/drive/MyDrive/DatasetCSI/train_DWT_5class_4.pt')\n",
    "test_dataset = torch.load('/content/drive/MyDrive/DatasetCSI/test_DWT_5class_4.pt')\n",
    "'''\n",
    "# Define the indices for the train and test sets\n",
    "train_indices = list(range(100, 950)) + list(range(1150, 1850))\n",
    "test_indices = list(range(100)) + list(range(950, 1150)) + list(range(1850, 2027))\n",
    "\n",
    "# Create TensorDataset for train and test sets\n",
    "train_dataset = TensorDataset(dataset.tensors[0][train_indices].to(device), dataset.tensors[1][train_indices].to(device))\n",
    "test_dataset = TensorDataset(dataset.tensors[0][test_indices].to(device), dataset.tensors[1][test_indices].to(device))\n",
    "\n",
    "# Define the sizes for your train and test sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "test_size = len(dataset) - train_size  # 20% for testing\n",
    "# Split the dataset into train and test\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "'''\n",
    "# Create DataLoader objects for training and testing\n",
    "batch_size = 64 # Adjust the batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6844,  0.5160,  0.1131,  1.0653,  1.9906, -0.1534,  2.1234]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.MaxPool1d(2, stride=2, padding=1)\n",
    "ar = torch.randn(1,7)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6844, 0.5160, 1.9906, 2.1234]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [723/3808, 875/3808, 755/3808, 723/3808, 732/3808]\n",
    "\n",
    "# Convert class_weights to a PyTorch tensor\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store training and validation losses\n",
    "#training_losses = []\n",
    "#validation_losses = []\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0003, momentum=0.9)\n",
    "\n",
    "# Your training loop\n",
    "for epoch in range(40):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    # Calculate and save training loss for this epoch\n",
    "    training_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    # Validation loss calculation\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    validation_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "    # Calculate and save validation loss for this epoch\n",
    "    validation_loss /= len(test_loader)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    # Print and/or save the losses if needed\n",
    "    print(f'Epoch [{epoch + 1}/{140}]')\n",
    "    print(f'Training Loss: {training_loss}')\n",
    "    print(f'Validation Loss: {validation_loss}')\n",
    "\n",
    "    # Your training loop continues...\n",
    "\n",
    "# At this point, you have lists training_losses and validation_losses\n",
    "# containing the training and validation losses for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.plot(validation_losses)\n",
    "ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images:{100 * correct / total} %')\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Set the network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())  # Convert labels to a NumPy array and extend the list\n",
    "        predicted_labels.extend(predicted.cpu().numpy())  # Convert predicted labels to a NumPy array and extend the list\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes=['gio', 'Laura', 'Fra', 'Andrea']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment=\"center\", color=\"black\")\n",
    "# Display the confusion matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/content/drive/MyDrive/mySuperFantasticModel.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
